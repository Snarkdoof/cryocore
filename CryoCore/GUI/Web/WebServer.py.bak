import sys
import select
import socket
import os
import os.path
import urllib
import mimetypes
import threading
import time
import re
import random

import gzip
import StringIO
import json
import cgi
import hashlib
import base64

# Verbose error messages from CGI module
import cgitb
cgitb.enable()

import BaseHTTPServer
import SocketServer

DB_TYPE="mysql"    

import MySQLdb

from CryoCore import API
from CryoCore.Core.PrettyPrint import *
from CryoCore.Core.Utils import *
#from Common.PictureSupplier import PictureSupplier
from CryoCore.Tools import TailLog, HUD
from CryoCore.Core.InternalDB import mysql as sqldb

global channel_ids 
global param_ids
global disablePic
channel_ids = {}
param_ids = {}
disablePic = False
WebSocketMagic = "258EAFA5-E914-47DA-95CA-C5AB0DC85B11"

DEBUG = False

def toUnicode(string):
    """
    Function to change a string (unicode or not) into a unicode string
    Will try utf-8 first, then latin-1.
    TODO: Is there a better way?  There HAS to be!!!
    """

    if string.__class__ != str:
        return string
    try:
        return unicode(string, "utf-8")
    except:
        pass
    return unicode(string, "latin-1")


def microsec_to_string(microsec):
    """
    Convert from million seconds to a decent string
    """

    str = ""

    sec = long(microsec)/1000000000
    # Now make this into "hours" "minutes" "seconds"
    hours = sec/3600
    if hours:
        sec -= hours*3600
        str = "%d h "%hours
        
    minutes = sec/60
    if minutes:
        sec -= minutes*60
        str += "%d min "%minutes

    str += "%d sec"%sec

    return str


class WatchList:
    def __init__(self):
        self.op_clock = 0
        
        self.channels = {} # channels[channel] = [param1, param2, ..]
        self.op_clocks = {}

    def reset(self):
        """
        Reset this session e.g. reset the data counters, allowing all
        data to be delivered again
        """
        self.op_clocks = {}
        
    def get_clock(self, channel, param):
        k = channel + "." + param
        if not self.op_clocks.has_key(k):
            self.op_clocks[k] = 0
        return self.op_clocks[k]

    def set_clock(self, channel, param, clock):
        self.op_clocks[channel + "." + param] = clock
    
    def update_parameter(self, id, timestamp, channel, name, value):

        if not channel in self.channels:
            self.channels[channel] = {}
        self.channels[channel][name] = (id, timestamp, channel, name, value)

    def delete_parameter(self, channel, name):
        if channel in self.channels:
            if name in self.channels[channel]:
                del self.channels[channel][name]
            if len(self.channels[channel]) == 0:
                del self.channels[channel]

    def add_parameter(self, channel, name):

        if not channel in self.channels:
            self.channels[channel] = {}
        if not name in self.channels[channel].keys():
            self.channels[channel][name] = None
            
    def get_parameters(self):

        result = []
        for channel in self.channels:
            for value in self.channels[channel].values(): 
                if value:
                    result.append(value)
        return result
    
    def get_channels(self):
        return self.channels.keys()
        
        
class LogDB(TailLog.TailLog):
    
    def __init__(self):
        TailLog.TailLog.__init__(self)

    def get_changes_by_time(self, args, 
                            start_time,
                            stop_time): 
        # TODO: Also do sessions, times and stuff here
        if args:
            sql = "AND " + args
        else:
            sql = ""

        rows = 0
        cursor = self._execute("SELECT * FROM log WHERE timestamp>? AND timestamp<? AND %s ORDER BY id"%sql,
                               [start_time, stop_time])
        return cursor
        
        
    def get_changes_by_id(self, args, min_id, limit):
        """
        return updates since last time and 
        """
        _last_id = min_id
        if not _last_id:
            cursor = self._execute("SELECT MAX(id) FROM log")
            row = cursor.fetchone()
            if row[0]:
                _last_id = max(row[0] - 10, 0)

        rows = 0
        SQL = "SELECT * FROM log WHERE id>? ";
        params = [_last_id]
        if len(args) > 0:
            SQL += "AND %s "%args[0]
            params += args[1]
        SQL += "ORDER BY id DESC "
        if limit:
            SQL += "LIMIT %s"
            params.append(int(limit))
        cursor = self._execute(SQL, params)
        return cursor

    def get_modules(self):
        """
        Return a list of modules that have been logging
        """
        cursor = self._execute("SELECT DISTINCT(module) FROM log")
        return cursor

    def get_log_levels(self):
        """
        Return a list of textual log levels that are available
        """
        return API.log_level_str.keys()

class DBWrapper:
    def __init__(self, status_db="System.Status.MySQL"):
        self.status_db = status_db
        self._dbs = {}
        
    def get_db(self, db_name):
        if not db_name in self._dbs.keys():
            self._dbs[db_name] = StatusDB(db_name = db_name, status_db = self.status_db)
            
        return self._dbs[db_name]

class StatusDB(sqldb):

    def __init__(self, name = "WebGui.StatusDB", db_name = None, status_db = "System.Status.MySQL"):

        self._cached_params = {}
        self.name = name
        self.log = API.get_log(self.name)
        cfg = API.get_config(status_db)
        if not cfg["db_name"]:
            cfg = API.get_config("System.InternalDB")
        sqldb.__init__(self, name, cfg, db_name = db_name)

        init_sqls = ["""CREATE TABLE IF NOT EXISTS status_view (
id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
name VARCHAR(255) NOT NULL UNIQUE,
description VARCHAR(2048) DEFAULT '',
owner VARCHAR(255) DEFAULT '',
last_op INT UNSIGNED DEFAULT 0)""",
                     """CREATE TABLE IF NOT EXISTS status_view_mapping (
viewid INT UNSIGNED,
paramid INT UNSIGNED,
data VARCHAR(255) DEFAULT '',
PRIMARY KEY(viewid, paramid))""",
                     """CREATE TABLE IF NOT EXISTS items (
item_key VARCHAR(255) PRIMARY KEY,
value TEXT)""",
"""CREATE TABLE IF NOT EXISTS ffs (
id INT AUTO_INCREMENT PRIMARY KEY,
ts TIMESTAMP DEFAULT current_timestamp,
simtime DOUBLE,
result VARCHAR(20),
description VARCHAR(256),
config TEXT
)
"""]
        self._init_sqls(init_sqls)


    def new_session(self, name=None, description=None):
        """
        Create a new, empty session
        """
        if not name:
            name = "s%d"%random.randint(0, 10000000)
        self._execute("INSERT INTO status_view (name, description) VALUES (%s, %s)", [name, description])

        # Return the session
        return self.get_session(name)

    def get_sessions(self):
        """
        Return all sessions
        """
        cursor = self._execute("SELECT id,name,description,owner FROM status_view")
        views = []
        for view_id, name, description, owner in cursor.fetchall():
            entry = {"id": view_id, "name": name}
            if description:
                entry["description"] = description
            if owner:
                entry["owner"] = owner
            views.append(entry)
        return views
        
    def get_session(self, name, create_if_missing=True):
        cursor = self._execute("SELECT id,name,description FROM status_view WHERE name=%s", [name])
        row = cursor.fetchone()
        if not row:
            if create_if_missing:
                print "Creating session", name
                self.new_session(name)
                return self.get_session(name, False)
            raise Exception("No session '%s'"%name)
        return {"id":row[0], "name":row[1], "description":row[2]}
    
    def get_session_by_id(self, session_id):
        if int(session_id) == 0:
            # Special case - no session really
            return {"id":0, "name":"no session", "description":""}

        cursor = self._execute("SELECT id,name,description FROM status_view WHERE id=%s", [session_id])
        row = cursor.fetchone()
        if not row:
            raise Exception("No session '%s'"%session_id)
        return {"id":row[0], "name":row[1], "description":row[2]}
    
    
    def reset_session(self, session=None, session_id=None):
        assert(session or session_id)
        if not session_id:
            session_id = session["id"]
        self._execute("UPDATE status_view SET last_op=0 WHERE id=%s", [session_id])
    def clear_session(self, session_id):
        self._execute("DELETE FROM status_view_mapping WHERE viewid=%s", [session_id])
        

    def _get_param_info(self, paramid):
        """
        Get the channel and name of a parameter
        """
        if not paramid in self._cached_params:
            SQL = "SELECT status_channel.name,status_parameter.name FROM status_channel,status_parameter "\
                "WHERE status_parameter.chanid=status_channel.chanid AND paramid=%s"
            cursor = self._execute(SQL, [paramid])
            row = cursor.fetchone()
            if not row:
                raise Exception("No parameter '%s'"%paramid)
            self._cached_params[paramid] = {"channel":row[0],
                                            "name":row[1]}
        return self._cached_params[paramid]
    
                
    ########### Available interface ############

    def get_last_status_values(self, session, max_time=None):
        """
        Return the last (paramid, id, timestamp, value) of all parameters of a session
        """
        res = []
        SQL = "SELECT paramid FROM status_view_mapping WHERE viewid=%s"
        cursor = self._execute(SQL, [session["id"]])
        for row in cursor.fetchall():
            SQL2 = "SELECT id, timestamp, value FROM status WHERE paramid=%s "
            paramid = row[0]
            params = [paramid]
            if max_time:
                SQL2 += "AND timestamp<%s "
                params.append(max_time)
            SQL2 += "ORDER BY timestamp DESC LIMIT 1"
            cursor2 = self._execute(SQL2, params)
            for num, ts, val in cursor2.fetchall():
                res.append((num, ts, paramid, val))
        return res
    

    def get_timestamps(self):
        """
        Return the smallest and largest timestamp (for relative clocks)
        """
        cursor = self._execute("SELECT MIN(timestamp), MAX(timestamp) FROM status")
        try:
            row = cursor.fetchone()
            return {"min":row[0], "max":row[1]}
        except:
            return {}

    def get_op_clock(self, session, max_time = None, since = 0):

        # Must get the max op_clock of all params of a session
        params = [since]
        if max_time:
            m = "timestamp < %s AND "
            params.append(max_time)
        else:
            m = ""
        SQL = "SELECT MAX(id) FROM status,status_view_mapping WHERE id>%s AND " + m + "viewid=%s AND status_view_mapping.paramid=status.paramid"
        params.append(session["id"])
        
        cursor = self._execute(SQL, params)
        row = cursor.fetchone()
        if not row:
            return since
        if row[0] == None:
            return since
        return int(row[0])
    
    def get_channels(self):
        cursor = self._execute("SELECT chanid, name FROM status_channel ORDER BY name")
        global channel_ids 
        channels = []
        for row in cursor.fetchall():
            if row[1] not in channel_ids:
                channel_ids[row[1]] = row[0]
            channels.append(row[1])
        return channels

    def get_params(self, channel):
        if not channel in channel_ids:
            self.get_channels()

        cursor = self._execute("SELECT paramid, name FROM status_parameter WHERE chanid=? ORDER BY name",[channel_ids[channel]])
        if DEBUG:
            self.log.debug("SELECT paramid, name FROM status_parameter WHERE chanid=? ORDER BY name" + str([channel_ids[channel]]))
        params = []
        global param_ids
        for row in cursor.fetchall():
            fullname = channel + "." + row[1]
            if not fullname in param_ids:
                param_ids[fullname] = row[0]
            params.append(row[1])
        return params

    def get_params_with_ids(self, channel):
        if not channel in channel_ids:
            self.get_channels()

        cursor = self._execute("SELECT paramid, name FROM status_parameter WHERE chanid=? ORDER BY name",[channel_ids[channel]])
        if DEBUG:
            self.log.debug("SELECT paramid, name FROM status_parameter WHERE chanid=? ORDER BY name" + str([channel_ids[channel]]))
        params = []
        global param_ids
        for row in cursor.fetchall():
            fullname = channel + "." + row[1]
            if not fullname in param_ids:
                param_ids[fullname] = row[0]
            params.append((row[0], row[1]))
        return params

    def get_data(self, params, start_time, end_time, since=0, aggregate=None):
        if len(params) == 0:
            raise Exception("No parameters given")

        p = [start_time, end_time, since]
        SQL = "SELECT id, paramid, timestamp, value FROM status WHERE timestamp>%s AND timestamp<%s AND id> %s AND ("
        for param in params:
            SQL += "paramid=%s OR "
            p.append(param)
        if aggregate is not None:
            SQL = SQL[:-4] + ") GROUP BY paramid, timestamp DIV %d" % aggregate
        else:
            SQL = SQL[:-4] + ") ORDER BY paramid, timestamp"

        #print SQL, str(p)
        cursor = self._execute(SQL, p)
        dataset = {}
        max_id = since
        for i, p, ts, v in cursor.fetchall():
            max_id = max(max_id, i)
            if p not in dataset:
                dataset[p] = []

            try:
                v = float(v)
            except:
                pass
            dataset[p].append((ts, v))
        return max_id, dataset

    def get_max_data(self, params, start_time, end_time, since=0, aggregate=None):
        if len(params) == 0:
            raise Exception("No parameters given")

        if not aggregate:
            raise Exception("Need aggregate value")

        p = [start_time, end_time, since]
        SQL = "SELECT timestamp, max(value) FROM status WHERE timestamp>%s AND timestamp<%s AND id> %s AND ("
        for param in params:
            SQL += "paramid=%s OR "
            p.append(param)
        SQL = SQL[:-4] + ") GROUP BY timestamp DIV %d" % aggregate

        API.get_log("WS").debug(SQL + "," + str(p))
        cursor = self._execute(SQL, p)
        dataset = {}
        max_id = since
        for ts, v in cursor.fetchall():
            try:
                v = float(v)
            except:
                pass
            dataset[ts] = v
        return 0, dataset

    def update_view(self, session, name, description):
        self._execute("UPDATE status_view SET name=%s, description=%s WHERE id=%s",
                      [name, description, session])


    def del_view(self, session):
        self._execute("DELETE FROM status_view WHERE id=%s",
                      [session])
        self._execute("DELETE FROM status_view_mapping WHERE viewid=%s",
                      [session])

    def get_view(self, session):
        """
        Return info about the given view + mapping of parameters to data
        """
        cursor = self._execute("SELECT name,description,owner FROM status_view WHERE id=%s", [session["id"]])
        row = cursor.fetchone()
        if not row:
            raise Exception("No view with id '%s'"%session)
        ret = {"name": row[0],
               "description": row[1],
               "owner": row[2]}

        cursor = self._execute("SELECT paramid,data FROM status_view_mapping WHERE viewid=%s", [session["id"]])
        mapping = {}
        for paramid,data in cursor.fetchall():
            mapping[paramid] = data
        ret["data"] = mapping

        # Map paramid to channel and name
        cursor = self._execute("SELECT status_parameter.paramid,status_channel.name,status_parameter.name " \
                                   "FROM status_channel,status_parameter,status_view_mapping WHERE " \
                                   "status_parameter.chanid=status_channel.chanid AND " \
                                   "status_parameter.paramid=status_view_mapping.paramid AND "\
                                   "status_view_mapping.viewid=%s", [session["id"]])
        params = {}
        for paramid, channel, name in cursor.fetchall():
            params[paramid] = [channel, name]
            
        ret["var_map"] = params;
        return ret

    def get_changes(self, since, session, start_time=None, stop_time=None, 
                    get_all=False, max_entries=1000):
        
        args = [session["id"], since]

        timelimits = " AND "
        if start_time:
            timelimits += "timestamp>%s AND "
            args.append(start_time)
        if stop_time:
            timelimits += "timestamp<%s AND "
            args.append(stop_time)
        timelimits = timelimits[:-5]
        
        if not get_all:
            # Get the max op_clock and value for all parameters of a session
            SQL = "SELECT status.paramid, id,value, timestamp FROM status, (SELECT MAX(id) AS maxid FROM status,status_view_mapping WHERE viewid=%s AND status_view_mapping.paramid=status.paramid AND id>%s" + timelimits +" GROUP BY status.paramid) innertable WHERE status.id=innertable.maxid ORDER BY id, status.paramid"
            #SQL = "SELECT status.paramid, id,value, timestamp FROM status,status_view_mapping WHERE viewid=%s AND status_view_mapping.paramid=status.paramid AND id>%s" + timelimits +" ORDER BY status.paramid"
        else: 
            # Want all values since last time
            SQL = "SELECT status.paramid, id,value, timestamp FROM status,status_view_mapping WHERE viewid=%s AND status_view_mapping.paramid=status.paramid AND id>%s " + timelimits + " ORDER BY id, status.paramid"
        if max_entries:
            SQL += " LIMIT %s"
            args.append(max_entries)
            
        cursor = self._execute(SQL, args)
        
        # Prepare the results and send them
        ret = []
        for (paramid, num, value, timestamp) in cursor.fetchall():
            #param_info = self._get_param_info(paramid)
            #ret.append((num, timestamp, param_info["channel"], param_info["name"], value))
            ret.append((num, timestamp, paramid, value))
        return ret

    def add_parameter_by_id(self, paramid, session, data=''):
        """
        Add parameter to session
        """        
        SQL = "REPLACE INTO status_view_mapping VALUES(%s,%s,%s)"
        cursor = self._execute(SQL, [session["id"], paramid, data])
        #SQL = "INSERT INTO status_view_mapping SELECT %s,paramid,%s FROM status_channel,status_parameter WHERE status_channel.chanid=status_parameter.chanid AND status_channel.name=%s AND status_parameter.name=%s"
        #cursor = self._execute(SQL, [session["id"], data, channel, parameter])

        return {"paramid":paramid}
    

    def add_parameter(self, channel, parameter, session, data=''):
        """
        Add parameter to session
        """        
        # We return the channel ID and parameter ID of this add
        SQL = "SELECT paramid,status_channel.chanid FROM status_channel,status_parameter WHERE status_channel.chanid=status_parameter.chanid AND status_channel.name=%s AND status_parameter.name=%s"
        cursor = self._execute(SQL, [channel, parameter])
        
        paramid, chanid = cursor.fetchone()
        
        SQL = "REPLACE INTO status_view_mapping VALUES(%s,%s,%s)"
        cursor = self._execute(SQL, [session["id"], paramid, data])
        #SQL = "INSERT INTO status_view_mapping SELECT %s,paramid,%s FROM status_channel,status_parameter WHERE status_channel.chanid=status_parameter.chanid AND status_channel.name=%s AND status_parameter.name=%s"
        #cursor = self._execute(SQL, [session["id"], data, channel, parameter])

        return {"paramid":paramid, "chanid":chanid}
    
        
    def del_parameter_by_id(self, paramid, session):
        """
        Remove a parameter from a view
        """
        SQL = "DELETE FROM status_view_mapping WHERE viewid=%s AND paramid=%s"
        self._execute(SQL, [session["id"], paramid])

    def del_parameter(self, channel, parameter, session):
        """
        Remove a parameter from a view
        """
        SQL = "SELECT paramid FROM status_channel,status_parameter WHERE status_channel.chanid=status_parameter.chanid AND status_channel.name=%s AND status_parameter.name=%s"
        cursor = self._execute(SQL, [channel, parameter])
        row = cursor.fetchone()
        if not row:
            raise Exception("No parameter: %s of channel %s"%(parameter, channel))
        SQL = "DELETE FROM status_view_mapping WHERE viewid=%s AND paramid=%s"
        self._execute(SQL, [session["id"], row[0]])

    def add_item(self, key, item):
        SQL = "REPLACE INTO items (item_key, value) VALUES (%s, %s)"
        self._execute(SQL, [key, item])

    def get_item(self, key):
        SQL = "SELECT value FROM items WHERE item_key=%s"
        cursor = self._execute(SQL, [key])
        row = cursor.fetchone()
        if row:
            return row[0]
        return ""
 
    def list_items(self):
        SQL = "SELECT item_key FROM items"
        cursor = self._execute(SQL)
        res = []
        for row in cursor.fetchall():
            res.append(row[0])
        return res

    def ffs_list(self, ts=None):
        if ts is None:
            ts = time.time()
        c = self._execute("SELECT id, UNIX_TIMESTAMP(ts), simtime, result, description FROM ffs WHERE simtime > %s", [ts])
        res = []
        for id, ts, simtime, result, desc in c.fetchall():
            res.append({"id": id, "ts": ts, "simtime": simtime, "result": result, "description": desc})
        c.close()
        return res

    def ffs_save(self, ts, config, res, desc=""):
        c = self._execute("INSERT INTO ffs (simtime, config, result, description) VALUES (%s, %s, %s, %s)", [ts, config, res, desc])
        c.close()

    def ffs_get(self, id):
        c = self._execute("SELECT UNIX_TIMESTAMP(ts), simtime, config, result, description FROM ffs WHERE id=%s", [id])
        row = c.fetchone()
        if not row:
            return {}
        ts, simtime, config, result, desc = row
        res = {
            "ts": ts,
            "simtime": simtime,
            "config": config,
            "result": result,
            "description": desc
        }
        c.close()
        return res

class MyWebServer(BaseHTTPServer.HTTPServer):
    """
    Non-blocking, multi-threaded IPv6 enabled web server
    """
    # DS: Temporarily disable ipv6
    #if socket.has_ipv6:
    #    address_family = socket.AF_INET6
        
    # Override that blasted blocking thing!
    def get_request(self):
        """Get the request and client address from the socket.
        Override to allow non-blocking requests.

        WARNING: This will make "serve_forever" and "handle_request"
        throw exceptions and stuff! Serve_forever thus does not work!
        """

        # Use select for non-blocking IO
        if select.select([self.socket], [], [], 1)[0]:
            return self.socket.accept()
        else:
            return None

# TODO: Implement class ThreadPoolMixIn  defining
#def process_request(self, request, client_address):
# Which queues requests on a queu and executes the handler
# with requests, client_address as parameter
#        """Start a new thread to process the request."""
#        t = threading.Thread(target = self.process_request_thread,
#                             args = (request, client_address))
#        if self.daemon_threads:
#            t.setDaemon (1)
#        t.start()
# where process_request_thread(self): is 
#        try:
#            self.finish_request(request, client_address)
#            self.close_request(request)
#        except:
#            self.handle_error(request, client_address)
#            self.close_request(request)



class MyWebHandler(BaseHTTPServer.BaseHTTPRequestHandler):
    """
    Handle requests
    """

    server_version = "UAV Onboard/0.1"

    def log_message(self, format, *args):
        """
        Override message logging - don't want reverse DNS lookups
        or output to stderr

        The first argument, FORMAT, is a format string for the
        message to be logged.  If the format string contains
        any % escapes requiring parameters, they should be
        specified as subsequent arguments (it's just like
        printf!).

        The client host and current date/time are prefixed to
        every message.

        """

        if self.server.cfg["log_requests"]:
            self.get_log().debug(format%args)

    def getPath(self, strip_args=False):
        """
        Get the unicode, unquoted path of the request
        """
        path = urllib.unquote(self.path)
        path = unicode(path, "utf-8", "replace")

        if strip_args and path.find("?") > -1:
            path = path[:path.find("?")]
        return path

    def failed(self, code, message = None):
        """
        Request failed, return error
        """
        
        try:
            if message:
                self.send_error(code, str(message))
            else:
                self.send_error(code)
        except Exception,e:
            print "Could not send error:",e
        return False

    def get_log(self):
        return API.get_log("WebGUI.Handler")
    
    def prepare_send(self, type, size=None, response=200, encoding=None, content_range=None):

        try:
#            self.server.log.debug("Sending %s"%response)
            self.send_response(response)
        except Exception, e:
            self.get_log().warning("Error sending response: %s"%e)
            return

        #self.send_header("date", makeRFC1123time(time.time()))
        self.send_header("server", self.server_version)
        self.send_header("Access-Control-Allow-Origin", "*")
        
        # Send type
        if type:
#            self.server.log.debug("Content-Type: %s "%type)
            self.send_header("Content-Type", type)

        if content_range:
#            self.server.log.debug("Content-Range: bytes %d-%d/%d"%content_range)
            self.send_header("Content-Range", "bytes %d-%d/%d"%content_range)

        self.send_header("Accept-Ranges", "bytes")

        if size:
#            self.server.log.debug("Content-Length: %s"%size)
            self.send_header("Content-Length",size)
        
        if encoding:
#            self.server.log.debug("Content-Encoding: %s"%encoding)
            self.send_header("Content-Encoding", encoding)
            
        if self.session:
            self.send_header("Set-Cookie", "session=%s"%self.session["id"])
        self.end_headers()

    def _to_file(self, path):
        """
        Return a valid file, send error and return None if not allowed
        """
        if not file:
            return self.failed(404, "No file specified")
        
        if not self.server.cfg["web_root"]:
            self.server.log.error("Internal error: 'web_root' config parameter does not exist")
            return self.failed(400)

        file_path = os.path.join(self.server.cfg["web_root"], path[1:])

        if not os.path.abspath(file_path).startswith(os.path.abspath(self.server.cfg["web_root"])):
            self.failed(403)
            return None
        
        if not os.path.exists(file_path):
            self.failed(404, "No such file '%s'"%file_path)
            return None
        return file_path
        
        
        
    def _send_image(self, path, fullpath=False):
        if not path:
            return self.failed(404, "No file specified")
        if fullpath:
            p = path
        else:
            p = self._to_file(path)
        if not p:
            self.server.log.info("Got request for '%s' which turned into None"%path)
            return self.failed(404, "Nothing know about '%s'"%path)
        
        if os.path.exists(p):
            data = open(p,"r").read()
            self.prepare_send("image/jpeg", len(data))
            self.wfile.write(data)
            self.wfile.close()
            return
        self.failed(404, "Missing file '%s'"%path)

    def add_url(self, _url, reset=False):
        """
        """
        import re
        m = re.match("/.*url=(.*)", _url)
        if not m:
            return

        url = m.groups()[0]
        if reset:
            self.server.player.clear()

        self.server.player.add_url(url)
        
    def do_POST(self):

        path = self.getPath()

        if path.startswith("/set"):
            length = int(self.headers.getheader('content-length'))
            print "POST data", length
            try:
                data = self.rfile.read(length)
                d = json.loads(urllib.unquote(data))
                print "Data is:", d
            except:
                self.failed(400, "Bad request")
            # Should insert into database
            db = self.get_db()
            for key in d:
                c = db._execute("SELECT name FROM status_parameter WHERE paramid=%s", [key])
                row = c.fetchone()
                c.close()
                if not row:
                    print "Bad parameter", key
                    return self.failed(400, "Bad parameter: %s" % key)

            # Have all keys, insert
            print "WILL INSERT"
            for key in d:
                params = []
                SQL = "INSERT INTO status (timestamp, paramid, value) VALUES "
                for ts, value in d[key]:
                    SQL += "(%s,%s,%s),"
                    params.append(ts)
                    params.append(key)
                    params.append(value)
                SQL = SQL[:-1]
                c = db._execute(SQL, params)

            self.send_response(200)
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            return

        if path != "/set_config":
            return self.failed(404)
        
        ctype, pdict = cgi.parse_header(self.headers.getheader('content-type'))
        if ctype == 'multipart/form-data':
            form = cgi.parse_multipart(self.rfile, pdict)
        elif ctype == 'application/x-www-form-urlencoded':
            length = int(self.headers.getheader('content-length'))
            form = cgi.parse_qs(self.rfile.read(length), keep_blank_values=1)
        else:
            form = {}
        #data = self.rfile.read(length)
        #self.server.log.debug("Got data:" + data)
        #form = cgi.FieldStorage(fp=self.rfile)
        self.server.log.debug("set config: " + str(form.keys()))

        if not form.has_key("version"):
            return self.send_error(400, "Missing version")
        if not form.has_key("json"):
            return self.send_error(400, "Missing config")
        
        if form.has_key("root"):
            root = form["root"].value
        else:
            root = None

        version = form["version"][0]
        serialized = form["json"][0]

        if path.startswith("/set_config"):
            try:
                self.server.log.info("Should save config" + " root:" + str(root) + ", version:" + str(version))

                self.server.log.info("Saving config '%s'"%version)

                cfg = API.get_config()
                
                # First we add the version if it doesn't already exist
                try:
                    cfg.add_version(version)
                except:
                    pass # Ignore any errors at this point
                cfg.deserialize(serialized, 
                                root=root, 
                                version=version,
                                overwrite=True)
                self.server.log.debug("Saved OK")
                return self.send_response(200)
            except Exception, e:
                self.server.log.exception("Setting config '%s'"%path)
                return self.failed(404, "Failed to save:" + str(e))


        return self.failed(300, "Should never get here")

    def _get_arg(self, args, name, default):
        if name in args:
            return args[name]
        return default
        
    def get_db(self):
        return self.server.db.get_db(self._get_params()["db"])

    def _do_GET_pic(self, path, args):
        """
        Divided into two different variants - if a timestamp is given,
        the image id to the correct image is given.  If img has a
        value, that image is returned with the correct quality

        Try to get a picture based on a timestamp, according to the
        given quality parameters
        - quality (typical values 0.4-0.9), default 0.9, 0 is thumbnail
        - scale (up to 1.0), default 1.0
        - crop (left,top,right,bottom), default whole image
        """
        global disablePic
        if disablePic:
            return self.failed(403, "Pictures disabled on basestation")
        
        if not "t" in args:
            if not "img" in args:
                return self.failed(400, "Need timestamp or picture id")

        if "t" in args:
            timestamp = float(args["t"])
            instrumentid = self._get_arg(args, "i", None)
            try:
                info = self.server.picture_supplier.get_image(timestamp, 
                                                              instrumentid)
            except:
                return self.failed(404, "No image for given time")

            data = json.dumps({"img":info["id"], "i":[info["timestamp"], info["instrument"], 
                                 info["lat"], info["lon"], info["alt"],
                                 info["q0"], info["q1"], info["q2"], info["q3"], 
                                 info["roll"], info["pitch"], info["yaw"], info["alt"]]})
            return self._send_html(data);
        
        img_id = args["img"]
        if (self._get_arg(args, "o", False)):
            # Request for the unmodified original 
            try:
                info = self.server.picture_supplier.get_image_by_id(img_id)
                self._send_image(info["path"], fullpath=True)
            except:
                self.failed(404)
            return

        quality = float(self._get_arg(args, "q", 0.9))
        scale = float(self._get_arg(args, "s", 1.0))
        crop = self._get_arg(args, "crop", None)
        histogram = self._get_arg(args, "h", None)
        headers_only = self._get_arg(args, "p", False)
        cached = self._get_cached(img_id, quality, scale, crop, histogram)
        if cached:
            return self._send_img_result(cached, headers_only)

        rotation = self.server.picture_supplier.get_rotation(img_id)

        crop_box = None
        if crop:
            c = crop.split(",")
            crop_box = (int(c[0]), int(c[1]), int(c[2]), int(c[3]))

        try:
            info = self.server.picture_supplier.get_image_by_id(img_id)
        except Exception, e:
            #self.server.log.exception("Getting picture")
            return self.failed(404, e)

        header = [info["timestamp"], info["instrument"], 
                  info["lat"], info["lon"], info["alt"],
                  info["q0"], info["q1"], info["q2"], info["q3"]]
        if histogram:
            data = self.server.picture_supplier.get_histogram(info["path"])
            content_type = "application/binary"
        else:
            #content_type = "image/jpeg"
            content_type = "image/png"
            # Got file info, prepare header and get data

            try:
                if quality == 0:
                    inf, data = self.server.picture_supplier.get_thumbnail(info["path"], rotation)
                    if len(data) == 0:
                        inf, data = self.server.picture_supplier.resample(info["path"], scale=0.2, rotation=rotation, filetype="png")
                else:
                    inf, data = self.server.picture_supplier.resample(info["path"], scale=scale,
                                                                 quality=quality, crop_box=crop_box, rotation=rotation, filetype="png")
            except Exception, e:
                self.server.log.exception("Getting picture")
                return self.failed(404, e)

            self.server.log.debug("Sending picture %s (%d bytes)"%(info["path"], len(data)))
            
        # We also send the physical size of the image as well as the
        # lat,lon of the boundingbox for it.  These are crude
        # estimations atm
        additional_info = {}
        for key in ["bb_size", "bb_sw", "bb_ne"]:
            if key in inf:
                additional_info[key] = inf[key]

        # Send data
        result = {"content-type":content_type,
                          "content-length":len(data),
                          "i":json.dumps(header),
                          "a": json.dumps(additional_info),
                          "data":data}
        self._cache_result(img_id, quality, scale, crop, histogram, result)
        self._send_img_result(result, headers_only)
        
    def _send_img_result(self, result, headers_only = False):
        self.send_response(200)
        for header in ["content-type", "content-length", "i", "a"]:
            if header in result:
                if headers_only and header == "content-length":
                    continue
                self.send_header(header, result[header])
        self.end_headers()
        if not headers_only:
            self.wfile.write(result["data"])
        self.wfile.close()
        return

    def _cache_result(self, img_id, quality, scale, crop, histogram, result):
        # Quick and dirty
	if not os.path.exists("/tmp/cache"):
		os.mkdir("/tmp/cache")

        cache_file = "/tmp/cache/%s_%s_%s_%s_%s"%(img_id, quality, scale, crop, histogram)
        f = open(cache_file, "w")
        f.write(result["data"])
        f.close()
        res = {}
        for k in result.keys():
            if k == "data":
                continue
            res[k] = result[k]
        f = open(cache_file + ".nfo", "w")
        f.write(json.dumps(res))
        f.close()
    
    def _get_cached(self, img_id, quality, scale, crop, histogram):
        cache_file = "/tmp/cache/%s_%s_%s_%s_%s"%(img_id, quality, scale, crop, histogram)
        
        if os.path.exists(cache_file):
            f = open(cache_file + ".nfo", "r")
            result = json.loads(f.read())
            f.close()
            f = open(cache_file, "r")
            result["data"] = f.read()
            f.close()
            return result
            
        return None
        
    def _get_additional_info(self, rotation, inf):
        """
        Physical size of bounding box + lat_lon of bounding box
        """
        additional = {}
        
        # We expect square pixels
        additional["px_size"] = rotation["image_width"]/inf["new_size"][0]

        #bounding-box size
        additional["bb_size"] = (inf["bb_size"][0]*additional["px_size"],
                                 inf["bb_size"][1]*additional["px_size"])
        
        # Lat-lon top left and bottom right corners
        # Latitude: 1 deg = 110.54 km
        # Longitude: 1 deg = 111.320*cos(latitude) km
        additional["bb_sw"] = (rotation["lat"] - (additional["bb_size"][0]/(2*110540.0)),
                               rotation["lon"] - (additional["bb_size"][1]/(2*112320.0*math.cos(math.radians(rotation["lat"])))))
        additional["bb_ne"] = (rotation["lat"] + (additional["bb_size"][0]/(2*110540.0)),
                       rotation["lon"] + (additional["bb_size"][1]/(2*112320.0*math.cos(math.radians(rotation["lat"])))))

        return additional
        
        
    def processItemRequest(self, path, args):
        data = None
        if path == "/item/list":
            l = self.get_db().list_items();
            data = json.dumps({"keys":l})
        elif path == "/item/add":
            self.get_db().add_item(args["key"], args["item"]);
            data = "";
        elif path == "/item/get":
            data = self.get_db().get_item(args["key"])
        if data == None:
            return self.failed(404, "Missing data")
        self._send_html(data)
    
    def processConfigRequest(self, path, args):
        #cfg = API.get_config()
        cfg = self.server.root_cfg
        res = None
        try:
            if path == "/cfg/get":
                res = cfg[args["param"]]
                #res = self.server.cfg.get(args["param"], absolute_path=True).get_value()
            elif path == "/cfg/set":
                try:
                    if args["value"].isdigit():
                        val = int(args["value"])
                    elif args["value"].replace(".","").isdigit():
                        val = float(args["value"])
                    else:
                        val = args["value"]
                except:
                    val = args["value"]
                cfg.set(args["param"], val, check=False)
                #cfg[args["param"]] = val
                #try:
                #    self.server.cfg.set(args["param"], args["value"], absolute_path=True)
                #except NoSuchParameterException:
                #    self.server.cfg.add(args["param"], args["value"])
                res = []
        except:
            self.server.log.exception("Config request failed: %s=%s"%(path, args))
            return self.failed(400, "Bad request")
        if res == None:
            return self.failed(404, "No such elmement %s"%path)
        self._send_html(json.dumps(res))

    def processFFSRequest(self, path, args):
        self.server.log.debug("FFS request, path: '%s' args: '%s'" % (path, str(args)))
        if path == "/ffs/store":
            if "desc" in args:
                desc = args["desc"]
            else:
                desc = ""
            self.get_db().ffs_save(args["ts"], args["config"], args["res"], desc)
            return self.failed(200)
        if path == "/ffs/get":
            res = self.get_db().ffs_get(args["id"])
            if not res:
                return self.failed(404)
            return self._send_html(json.dumps(res))
        if path == "/ffs/list":
            if ("ts" in args):
                res = self.get_db().ffs_list(args["ts"])
            else:
                res = self.get_db().ffs_list()
            if not res:
                return self.failed(404)
            return self._send_html(json.dumps(res))
        self.failed(404)

    def do_GET(self):
        try:
            self._do_GET()
        except:
            self.server.log.exception("In GET")

    def _get_params(self):
        import urlparse
        path = self.getPath()
        if path.find("?") > -1:
            args = cgi.parse_qs(path[path.find("?")+1:])
            for key in args:
                args[key] = args[key][0]
            path = path[:path.find("?")]
        else:
            args = {}

        if not "ts" in args:
            args["ts"] = None

        if not "db" in args:
            args["db"] = None
        return args
            

    def _do_ws_request(self):
        """
        Process a web socket request
        """
        headers = self.headers
        self.server.log.debug("Processing web socket request")
        valid = True
        if "upgrade" in headers.keys():
            if headers["upgrade"] == "websocket":
                self.send_response(101)
                # Handshake
                if "cookie" in headers.keys():
                    self.send_header("Cookie", headers["cookie"])
                self.send_header("Connection", "Upgrade")
                self.send_header("Upgrade", "websocket")
                self.send_header("Sec-WebSocket-Version", 13)
                the_string = headers["sec-websocket-key"] + WebSocketMagic;
                m = hashlib.sha1()
                m.update(the_string)
                self.send_header("Sec-WebSocket-Accept", base64.b64encode(m.digest()))
        else:
            return self.error(400, "Unsupported request")

        path = self.getPath(strip_args=True)
        if path == "/hud":
            # Head up display 
            class fakeit:
                def __init__(self, rfile, wfile):
                    self.rfile = rfile
                    self.wfile = wfile
                def send(self, data):
                    return self.wfile.write(data)
                def recv(self, maxlen):
                    return self.rfile.read(maxlen)

            f = fakeit(self.rfile, self.wfile)
            hud = HUD.HUDProvider(f)
            hud.start()
            return

    def _runShipSim(self, rotation, ts):
        from Leroy.Sim.MCC import MCWrapper
        wrapper = MCWrapper(self.get_db())
        res = wrapper.run_small_sim(float(rotation), int(ts))
        return res

    def _runFFSim(self, config, ts):

        from Leroy.Sim.MCC import MCWrapper
        wrapper = MCWrapper(self.get_db())
        res = wrapper.run_big_sim(config, int(ts))
        return res

    def _do_GET(self):

        if "upgrade" in self.headers.keys():
            return self._do_ws_request()


        self._compress = False
        if "Accept-Encoding" in self.headers:
            if "gzip" in self.headers["Accept-Encoding"]:
                self._compress = True

        path = self.getPath(strip_args=True)
        args = self._get_params()

        #self.server.log.debug("Got request for '%s'"%path)
        #print "REQUEST:", path, args
        self.session = None

        if path.startswith("/cfg"):
            return self.processConfigRequest(path, args)
        if path.startswith("/ffs/"):
            return self.processFFSRequest(path, args)

        if path.startswith("/feedback"):
            if ("text" not in args or "ts" not in args):
                return self.failed(400, "Need both text and ts arguments")
            self.server.status["feedback"].set_value(args["text"], timestamp=args["ts"])
            return self.send_response(200)

        # Picture request?
        try:
            if path.startswith("/pic"):
                return self._do_GET_pic(path, args)
        except:
            self.server.log.exception("Getting picture")
            return self.failed(500, "unknown error")

        if path.startswith("/item/"):
            return self.processItemRequest(path, args);
        
        if path.startswith("/list_sessions"):
            try:
                sessions = self.get_db().get_sessions()
                self._send_html(json.dumps({"sessions": sessions}))
            except Exception, e:
                return self.failed(500, "Exception getting sessions: %s"%e)

        if "session" in args:
            self.session = self.get_db().get_session_by_id(args["session"])

        # Prioritize argument based to allow multiple browser tabs with different sessions (or views)
        # Cookies are used to persist the last open view
        if not self.session and "Cookie" in self.headers:
            for cookie in self.headers["Cookie"].split(";"):
                (name, value) = cookie.split("=",1)
                if name.strip() == "session":
                    try:
                        self.session = self.get_db().get_session_by_id(value.strip())
                    except Exception, e:
                        self.session = self.get_db().new_session()
                    break

        if path.startswith("/newsession"):
            self.session = self.get_db().new_session()
            self._send_html(json.dumps({"sessionid":self.session["id"]}))
            return

            #self.session = self.get_db().new_session()

        if self.getPath().find("sessionrst") > -1:
            self.get_db().reset_session(self.session)

        if self.getPath().find("sessionclr") > -1:
            self.get_db().clear_session(self.session["id"])
            self.send_response(200)
            return
            
        if path.startswith("/save_view"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")

            name = self._get_arg(args, "name", None)
            description = self._get_arg(args, "desc", None)
            self.get_db().update_view(self.session["id"], name, description)
            self.send_response(200)
            return

        if path.startswith("/del_view"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            self.get_db().del_view(self.session["id"])
            self.send_response(200)
            self.send_header("Set-Cookie", "session=0");
            self.end_headers();
            return

        if path.startswith("/fullstate"):
            vals = self.get_db().get_last_status_values(self.session, args["ts"])
            return self._send_html(json.dumps(vals))

        if path.startswith("/state"):
            if not "since" in args:
                args["since"] = 0
                return self.failed(400, "Refusing state call without op_clock")

            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            retval = {
                "op_clock":self.get_db().get_op_clock(self.session, args["ts"], args["since"]),
                "server_time":time.time()
                };
            return self._send_html(json.dumps(retval))
            
        if path.startswith("/clock"):
            if not "since" in args:
                args["since"] = 0
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            clock = "%d"%self.get_db().get_op_clock(self.session, args["ts"], args["since"])
            self.prepare_send("text/html", len(str(clock)))
            self.wfile.write(str(clock))
            self.wfile.close()
            return

        if path.startswith("/server_time"):
            self._send_html(json.dumps({"time": time.time()}));
            return

        if path.startswith("/ts"):
            info = self.get_db().get_timestamps();
            self._send_html(json.dumps(info))
            return

        if path.startswith("/img/"):
            return self._send_image(path)

        if path.startswith("/list_channels_and_params_full"):
            return self._list_channels_and_params_full()        
        
        if path.startswith("/list_channels_and_params"):
            return self._list_channels_and_params()

        if path.startswith("/list_channels"):
            return self._list_channels()

        if path.startswith("/list_view"):
            return self._list_view(self.session)
        
        if path.startswith("/list_params/"):
            channel = path[13:]
            return self._list_params(channel)
        if path.startswith("/add_param/"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            # Will be /add_param/channel/param
            try:
                if path[11:].find("/") == -1:
                    data = self._get_arg(args, "data", None)
                    paramid = int(path[11:])
                    res = self.get_db().add_parameter_by_id(paramid, self.session, data)
                else:
                    (channel, param) = path[11:].split("/",1)
                    data = self._get_arg(args, "data", None)
                    self.get_log().debug("Adding parameter: %s from %s to session %s (%s)"%(param, channel, self.session, data))
                    res = self.get_db().add_parameter(channel, param, self.session, data)
                self._send_html(json.dumps(res))
                return
                #self.send_response(200)
            except MySQLdb.IntegrityError, e:
                # Already have this parameter associated
                return self.send_response(200)
            except:
                self.get_log().exception("Adding watch")
                self.failed(400) # Bad request
            return
        
        if path.startswith("/del_param/"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            try:
                if path[11:].find("/") == -1:
                    paramid = int(path[11:])
                    self.get_db().del_parameter_by_id(paramid, self.session)
                else:
                    # Will be /del_param/channel.param
                    (channel, param) = path[11:].split("/",1)
                    self.get_db().del_parameter(channel, param, self.session)
                self.send_response(200)
            except:
                self.failed(400) # Bad request
            return

        if path.startswith("/getcompc/"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            since=path[10:]
            if not since:
                since = 0
            html = self._get_compact_changes(since)
            self._send_html(html)
            return
            
        if path.startswith("/get_changes/"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            since=path[13:]
            if not since:
                since = 0
            if not "st" in args:
                args["st"] = None
            html = self._get_changes(since, start_time=args["st"], stop_time=args["ts"])
            self._send_html(html)
            return

        if path.startswith("/get_plot_changes/"):
            if not self.session:
                return self.failed(500, "Invalid session, load /newsession")
            since = self._get_arg(args, "since", 0)
            start_time = self._get_arg(args, "start_time", None)
            end_time = self._get_arg(args, "end_time", None)

            if DEBUG:        
                self.server.log.debug("_get_plot_changes(%s,%s, %s)"%\
                                          (since, start_time, end_time))

            ret = self._get_plot_changes(since, start_time, end_time)
            if ret:
                self._send_html(ret)
            else:
                self.failed(404)
            return

        if path.startswith("/get_trios_plot/"):
            html = self._get_trios_plot()
            if html:
                self._send_html(html)
            else:
                self.failed(404)
            return

        if path.startswith("/list_log_modules"):
            html = self._list_log_modules();
            if html:
                self._send_html(html)
            else:
                self.failed(404)
            return

        if path.startswith("/list_log_levels"):
            html = self._list_log_levels();
            if html:
                self._send_html(html)
            else:
                self.failed(404)
            return

        if path.startswith("/get_logs/"):
            if not "st" in args:
                args["st"] = None
            elems = path[1:].split("/")
            if len(elems) > 1:
                if not elems[1].upper() in API.log_level_str:
                    level = API.log_level_str["DEBUG"]
                else:
                    level = API.log_level_str[elems[1].upper()]
            if len(elems) > 2:
                module = str(elems[2])
            else:
                module = ""
            if len(elems) > 3:
                since = str(elems[3])
            else:
                since = 0
            
            html = self._get_logs(level, module, since, 
                                  min_time=args["st"], max_time=args["ts"])
            if html:
                self._send_html(html)
            else:
                self.failed(404)
            return

        if path.startswith("/get_config_versions"):
            cfg = API.get_config()
            versions = cfg.list_versions()
            serialized = json.dumps(versions)
            self._send_html(serialized)
            return
            
        if path.startswith("/get_config"):
            try:
                if "root" in args:
                    config_root = args["root"]
                else:
                    config_root = None
                if "version" in args:
                    version = args["version"]
                else:
                    #self.server.log.debug("No version, using default")
                    version = "default"
                #self.server.log.debug("Request for config version '%s' (%s)"%(version, args))
                cfg = API.get_config(config_root, version=version)
                serialized = cfg.serialize()
                return self._send_html(serialized)
            except:
                self.server.log.exception("Getting config '%s'"%path)
                return self.failed(404, "Unknown path '%s'"%path)
        
        if path.startswith("/get"):
          # List of parameters to get, and a time window is required
          if not "params" in args:
            return self.failed(500, "Missing parameter list")

          if not "start" in args:
            return self.failed(500, "Missing start")

          if not "end" in args:
            return self.failed(500, "Missing end")

          try:
            params = json.loads(args["params"])
            if len(params) == 0:
              return self.failed(500, "Missing parameters")
              
          except:
            return self.failed(500, "Bad parameter list")
          if "since" in args:
            since = int(args["since"])
          else:
            since = 0
          if "aggregate" in args:
            aggregate = int(args["aggregate"])
          else:
            aggregate = None
          # Now get the data!
          if (path.startswith("/getmax")):
              ret = self._get_max_data(params, args["start"], args["end"], since, aggregate)
          else:
              ret = self._get_data(params, args["start"], args["end"], since, aggregate)
          if ret:
            ret["ts"] = time.time()
            print "Got data", ret
            self._send_html(json.dumps(ret))
          else:
            self.failed(404)
          return

        if path.startswith("/sim/simple"):
            if not "rotation" in args:
                return self.failed(400, "Missing rotation")
            if not "ts" in args:
                return self.failed(400, "Missing timestamp")
            ret = self._runShipSim(args["rotation"], args["ts"])
            self._send_html(json.dumps(ret))
            return

        if path.startswith("/sim/ffs"):
            if "config" not in args:
                return self.failed(400, "Missing config")
            if "ts" not in args:
                return self.failed(400, "Missing timestamp")
            ret = self._runFFSim(json.loads(args["config"]), args["ts"])
            self._send_html(json.dumps(ret))
            return

        # Just look for the file
        if path == "/":
            file_path = self._to_file("/index.html")
        else:
            file_path = self._to_file(path)
            
        if file_path:
            response = 200;
            content_range = None
            ftype = mimetypes.guess_type(file_path)[0]
            if "Range" in self.headers:
                response = 206;
                r = self.headers["Range"]
                if not r.startswith("bytes="):
                    self.failed(400, "Bad request range")
                start, end = r[6:].split("-")
                f = open(file_path, "r")
                f.seek(int(start))
                fsize = os.path.getsize(file_path)
                if not end:
                    content = f.read()
                    content_range = (int(start), len(content)+int(start)-1, fsize)
                else:
                    content = f.read(int(end)-int(start))
                    content_range = (int(start), int(end), fsize)
            else:            
                content = open(file_path, "r").read()
                if ftype =="text/html" or ftype == "application/javascript":
                    content = self._replace_base_path(content)

            self._send_html(content, ftype, response=response, content_range=content_range)

    def _replace_base_path(self, content):
        """
        Allow config of base-path, allowing us to move some library stuff
        to another machine if we want to
        """
        
        if self.server.cfg["base_path"]:
            return content.replace("_BASE_PATH_", self.server.cfg["base_path"])
        return content.replace("_BASE_PATH_", "")
    
    def _list_channels_and_params(self):
        """
        Return all channels and their parameters as one giant json dump.
        """
        channelsAndParams = {}
        for channel in self.get_db().get_channels():
            params = self.get_db().get_params(channel)
            channelsAndParams[channel] = params
        data = json.dumps({"channels":channelsAndParams})
        self._send_html(data)

    def _list_channels_and_params_full(self):
        """
        Return all channels and their parameters as one giant json dump.
        """
        channelsAndParams = {}
        for channel in self.get_db().get_channels():
            params = self.get_db().get_params_with_ids(channel)
            channelsAndParams[channel] = params
        data = json.dumps({"channels":channelsAndParams})
        self._send_html(data)
    
    def _list_view(self, session):
        ret = self.get_db().get_view(session)
        self._send_html(json.dumps({"view": ret}))
        
    def _list_channels(self):
        """
        Create HTML of the channels - use a table
        """
        
        channels = []
        for channel in self.get_db().get_channels():
            channels.append(channel)
        self._send_html(json.dumps({"channels":channels}))

    def _list_params(self, channel):
        """
        Create HTML of the params of a channel - will be put into a table
        """
        self._send_html(json.dumps({"params": self.get_db().get_params(channel)}))
        return
        html = ""
        for param in self.get_db().get_params(channel):
            html += "<div class='param'><a href='javascript:add_param(\"%s\",\"%s\")'>%s</a></div>\n"%(channel, param, param)
        self._send_html(html)

    def _get_plot_changes(self, since, start_time, end_time):
        """
        Return a list of changes for all subscribed params suitable for
        a data plot. They are ordered by name,timestamp

        Format returned is "{"max_id":id, "data":{name: (timestamp,value)}\n"

        """
        max_id = int(since)
        dataset = {}
        for (num, timestamp, paramid, value) in \
                self.get_db().get_changes(since, 
                                           start_time=start_time, 
                                           get_all=True, 
                                           stop_time = end_time, 
                                           session=self.session,
                                           max_entries=12000):
            # Only add if the value is a number!
            if not paramid in dataset:
                dataset[paramid] = []
            try:
                dataset[paramid].append([float(timestamp), float(value)])
                if num > max_id:
                    max_id = num
            except Exception, e:
                dataset[paramid].append([float(timestamp), value])
        ret = {"max_id": max_id,
              "data": dataset}
        return json.dumps(ret)

    def _get_data(self, params, start_time, end_time, since=0, aggregate=None):
        """
        Return the dataset of the given parameters
        """
        max_id, dataset = self.get_db().get_data(params, start_time, end_time, since, aggregate)
        return {"max_id": max_id, "data": dataset}
        return json.dumps({"max_id": max_id, "data": dataset})

    def _get_max_data(self, params, start_time, end_time, since=0, aggregate=None):
        """
        Return the max values of the given parameters
        """
        max_id, dataset = self.get_db().get_max_data(params, start_time, end_time, since, aggregate)
        return {"max_id": max_id, "data": dataset}
        return json.dumps({"max_id": max_id, "data": dataset})

    def _get_trios_plot(self):
        """
        Return the last samples of the two TriOS spectrometers.
        
        Format returned is "up/down|timestamp|integrationtime|val1|val2|...|val255\n"
        Notice that value 0 is not available, it's always 0 anyways
        """
        if not self.server.trios:
            raise Exception("Missing Trios")

        dataset = {}
        html = ""
        for (instrument, timestamp, integration_time, values) in self.server.trios.get_last_samples():
            if not instrument in dataset:
                dataset[instrument] = {}
            dataset[instrument]["integration_time"] = integration_time
            dataset[instrument]["timestamp"] = time.ctime(timestamp)
            dataset[instrument]["data"] = []
            i = 0
            for value in values:
                dataset[instrument]["data"].append((i, value))
                i+= 1
        return json.dumps(dataset)

    def _list_log_modules(self):
        cursor = self.server._log_db.get_modules()
        modules = []
        for row in cursor:
            modules.append(row[0])
        
        return json.dumps(modules)
    
    def _list_log_levels(self):
        levels = self.server._log_db.get_log_levels()
        return json.dumps(levels)

    def _get_logs(self, log_level = 0, module = "", since = 0, 
                  limit = 1000, min_time = None, max_time = None):
        """
        Return log messages of the given log level.
        if module is given, only log messages from that module (and of the correct
        log levels) will be returned.

        TODO: start-time, end_time.
        """

        # If log_level is a string, convert it
        if log_level in API.log_level_str.keys():
            log_level = API.log_level_str[log_level]
        elif log_level not in API.log_level.keys():
            log_level = API.log_level_str["DEBUG"] # DEFAULT show all

        dataset = []
        query = "level >= %s"
        params = [log_level]
        if module:
            query += " AND module=%s"
            params.append(module)

        if min_time:
            query += " AND time>%s"
            params.append(min_time)
        if max_time:
            query += " AND time<%s"
            params.append(max_time)
        cursor = self.server._log_db.get_changes_by_id((query, params), since, limit)
        largest_id = 0
        for row in cursor.fetchall():
            if row[TailLog.ID] > largest_id:
                largest_id = row[TailLog.ID]
            dataset.append((row[TailLog.ID],
                            row[TailLog.TEXT],
                            API.log_level[row[TailLog.LEVEL]],
                            time.ctime(row[TailLog.TIMESTAMP]),
                            row[TailLog.LINE],
                            row[TailLog.FUNCTION],
                            row[TailLog.MODULE],
                            row[TailLog.LOGGER]))
        dataset.reverse()
            #dataset.append(list(row))
        #if len(dataset) > 0:
        #    self.server._last_log_id = dataset[-1][TailLog.ID]
            
        return json.dumps({"max_id":largest_id, "data":dataset})

    def _get_compact_changes(self, since):
        """
        Return changes since time X as a list in JSON [LineNum:
        name,value, ...] where num is from 0
        and up
        Also contains "time": with the current server time and
        "mtime": with the highest sample time (the last sample)
        """
        res = {"time":int(time.time())}
        newest_time = 0
        i=0
        rows =  self.get_db().get_changes(since, session=self.session)
        if rows:
            for (_id, timestamp, paramid, value) in rows:
                if timestamp > newest_time:
                    newest_time = timestamp
                try:
                    value = int(value)
                except:
                    pass # TODO: Do this nicer!

                res[i] = (_id, value)
                i += 1
        res["mtime"] = int(newest_time) #time.ctime(newest_time)
        return json.dumps(res)
        
    def _get_changes(self, since, start_time=None, stop_time=None):
        """
        Return changes since time X as a map in JSON {LineNum:
        (ID,timestamp,channel,name,value), ...} where num is from 0
        and up
        
        """
        #return json.dumps(self.get_db().get_changes(since))

        res = {}
        
        i=0
        rows = self.get_db().get_changes(since, session=self.session, start_time=start_time, stop_time=stop_time)
        if rows:
            for (id, timestamp, paramid, value) in rows:
                try:
                    value = float(value)
                except:
                    pass # TODO: Do this nicer!

                res[i] = (id, timestamp, paramid, value)
                i += 1

        return json.dumps(res)

    def _send_html(self, html, mimetype="text/html", response=200, content_range=None):
        
        # Only compress text if > 100 bytes
        if mimetype and mimetype.startswith("text") and self._compress and len(html) > 100: 
            encoding = "gzip"
            compressed = StringIO.StringIO()
            zipped = gzip.GzipFile(mode="w", fileobj=compressed, 
                                   compresslevel=9)
            zipped.write(html)
            zipped.close()
            html = compressed.getvalue()
        else:
            encoding = None

        self.prepare_send(mimetype, len(html), encoding=encoding, 
                          response=response, content_range=content_range)
        self.wfile.write(html)
        self.wfile.close()
        

        
class WebServer(threading.Thread):

    def __init__(self, port, db, stop_event):
        threading.Thread.__init__(self)
        print "Starting WebServer on port %s"%port

        self.stop_event = stop_event
        
        self.log = API.get_log("WebGUI")
        self.cfg = API.get_config("System.WebServer")
        self.cfg.require(["web_root"])
        
        self.log.debug("Initializing WebServer")
        self.server = MyWebServer(('0.0.0.0', int(port)), MyWebHandler)
        self.server.cfg = self.cfg
        
        self.server.root_cfg = API.get_config()
        self.server.status = API.get_status("System.WebServer")
        
        self.server.db = db
        self.server.picture_supplier = None #PictureSupplier()

        try:
            from Instruments.TriOS.TriOS import DBDump
        #self.server.trios = DBDump("UAV/trios.sqlite") # Replace with Postgres
            self.server.trios = DBDump("TriOS") 
        except:
            self.server.trios = None

        self.server._log_db = LogDB()
        self.server.log = self.log

        self.log.debug("WebServer initialized OK")

    def run(self):
        while not self.stop_event.is_set():
            try:
                self.server.handle_request()
            except Exception,e:
                # Ignore these, Just means that there was no request
                # waiting for us
                pass

        self.log.info("Stopped")

    def stop(self):
        print "Stopping"
        self.running = False

        self.server.socket.close()


if __name__ == "__main__":

    socket.setdefaulttimeout(5.0)
    
	
    #if len(sys.argv) == 2:
    #    db = StatusDB(sys.argv[1])
    #else:
    #    db = StatusDB()

    stop_event = threading.Event()
    if len(sys.argv) > 1:
        db = DBWrapper(status_db = sys.argv[1])
    else:
        db = DBWrapper()
    ws = WebServer(4321, db, stop_event)
    if "--disable-pic" in sys.argv:
        disablePic = True
    else:
        disablePic = False
    ws.start()
    
    try:
        raw_input("WebServer running on port 4321, press ENTER to stop it")
    except:
        pass

    print "Stopping server"
    stop_event.set()

    API.shutdown()
    
